+++
title = "Protobufs are cool"
date = 2024-02-19T14:57:48-05:00
images = []
tags = ['tech', 'protobufs']
categories = []
draft = true
+++

For a couple years now, I've been leading a team at work that builds tools & infra around our usage of schemas. Stripe almost exclusively uses [Protocol Buffers](https://protobuf.dev) (protobufs for short) for our schemas, and I think the tech here is pretty cool!

<!--more-->

# What's a protobuf?

First, let's go through an example of using protobufs.

## A worked example

Let's say I have a Python program that needs to pass some data to a Ruby program. Let's say it's some information about a set of users.

I can use a protobuf to do this. First, I write a file describing the data:

```protobuf
// program_output.proto
syntax = "proto3";

package my.awesome.program;

// Some information about our users.
message User {
    string id = 1;
    string name = 2;
}

// The actual output format of our Python program.
message ProgramOutput {
    // A "repeated" field, which contains multiple users.
    repeated User users = 1;
}
```

This is a protobuf file. It follows the [Protocol Buffer file syntax](https://protobuf.dev/programming-guides/proto3/).

Next, I can use the protobuf compiler, `protoc`, to turn this file into a Python library. I run:

```bash
protoc --python_out=. program_output.proto
```

This outputs a Python file, `program_output_pb2.py`:
```python
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: program_output.proto
"""Generated protocol buffer code."""
# some generated code follows...
```

I can import this in my Python program, and use it to serialize data:
```python
// my_program.py
from program_output_pb2 import User, ProgramOutput
output = ProgramOutput(
  users=[
    User(id="1", name="me"),
    User(id="2", name="you"),
  ]
)

with open('output.bin', 'wb') as output_file:
  output_file.write(output.SerializeToString())
```

When I run this, I get some binary data in `output.bin`. I can then deserialize this in Ruby, by first generating a Ruby library:
```bash
protoc --ruby_out=. program_output.proto
cat program_output_pb.rb
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: program_output.proto
# more generated code follows...
```

Then using that in a Ruby program:
```ruby
# my_program.rb
require_relative 'program_output_pb.rb'

f = File.open('output.bin', 'rb')
o = My::Awesome::Program::ProgramOutput.decode(f.read)
puts o.users
```

When I run that, I get the input back, in nice Ruby objects:
```bash
ruby my_program.rb
<My::Awesome::Program::User: id: "1", name: "me">
<My::Awesome::Program::User: id: "2", name: "you">
```

That, in a nutshell, is what protobuf is -- it's a way to describe data & de/serialize it, and it lets you pass stuff between different programs and different languages in a way that makes sense.

TODO:
- compatibility semantics

# What's cool about protobufs?

## Protobufs are human-readable

The syntax for protobufs is _really_ lightweight, and a lot of it is pretty intuitive. If you look back at our `program_output.proto`, you can immediately see how you'd add a new field to one of our messages, or a new message type. This is really great, because protobufs have to be read & written by all sorts of programmers working in all sorts of languages. At work, I almost never have to tell someone how to express something in protobuf; it's almost always other stuff that folks have questions about.

## They work cross-language

As you saw in the example above, protobufs let you take data from a program written in one language, and pass it to a program written in a totally different language. 

What's even better is that often, the clients in each language quite often feel "normal" for that language. What I mean by that is, the protobuf client in e.g. Python will adhere closely to Python language norms, like class and method names will be capitalized / scoped like you'd expect in Python, or the types of values that end up getting output by those classes are just normal Python types. You end up feeling like you're just writing normal Python code, instead of (as happens often in some frameworks) needing to write alien-looking code in some parts of your codebase. That might sound trivial, but I've found that in practice, minimizing programmer surprise like this avoids a major source of bugs.

This isn't always true, mind you. In particular, I've found that the Ruby bindings are pretty rough, in part because they're Google-maintained and Google basically doesn't use Ruby anywhere. But for most other languages, this is the case.

## They let you use the right tool for the job

This is a consequence of the above, sort of. When starting a project, I often find myself stuck picking a language, because different corners of the project are best-served with different languages. For example, it's hard to beat Python if you're doing scientific computation -- `numpy` and `pandas` are wildly popular and effective tools. But for webapps, I've really enjoyed working in Ruby (Rails) or Javascript. What if I want to build a webapp that does some scientific computation?

Protobufs make it a lot easier to say "yes, and" to programming languages. You can just use whatever tool is good for the job, knowing you'll have a nice way to pass your data around regardless of the language you're using.

TODO:
- Interfaces first

# Can't I just use JSON?

Let me tell you a story, hopefully one that'll be familiar.

> - Christine hops on call w/Sam, manager
> - New feature exposing user birthdays to do age-filtering
> - MVP, Ruby dump to JSON
> - Fast forward
> - Janet needs to add a new field
>   - Needs to track down where the Ruby code is & read it
> - Gets paged into an incident
> - `KeyError`

# Some not-so-cool things

- Controlled by Google
    - Semi-federated model
    - Changes are hard, esp. for some languages (Ruby)
    - Language bindings vary in quality
- Some things are weirdly/badly designed
    - `optional`
    - Editions
    - Extensions
    - Ruby language bindings